# ğŸ¦¥ Unsloth Fine-Tune Hub (Colab Edition)

A comprehensive Colab-based interface designed to simplify and simulate the fine-tuning of popular language models using the [Unsloth](https://github.com/unslothai/unsloth) library and [Gradio](https://www.gradio.app/) UI components. Ideal for experimentation, educational demos, and prototyping scalable LLM pipelines.

Built and curated by [Raghav](https://github.com/Raghav0079), this tool bridges cutting-edge optimization with user-friendly interaction.

---

## âœ¨ Core Features

- ğŸ” **Model Selection**  
  Fine-tune across major LLM architectures: **LLaMA-2**, **Mistral**, and **Falcon**, all integrated via dropdown for easy selection.

- ğŸ“Š **Hyperparameter Control**  
  Dynamically adjust key parameters like **learning rate** and **batch size** â€” no code edits required.

- ğŸ“ **Custom Dataset Upload**  
  Accepts training files in **.csv** and **.jsonl** format with auto-validation and status feedback.

- ğŸ§ª **Simulated Fine-Tuning Preview**  
  See how your settings would be applied, ideal for understanding workflows before jumping into compute-heavy training.

- ğŸ“ˆ **Roadmap Features**  
  Coming soon: Full integration of Unslothâ€™s training APIs and **WandB logging** for experiment tracking.

---

## ğŸš€ Quickstart Guide

### 1. Open in [Google Colab](https://colab.research.google.com/)
> Make sure you have GPU runtime enabled (under *Runtime > Change runtime type*)

### 2. Run Setup Cells Sequentially
Each cell is clearly labeled:
- Install dependencies: `gradio`, `transformers`, `unsloth`, `accelerate`, `datasets`
- Import all relevant libraries
- Check GPU availability
- Define the placeholder `fine_tune()` function
- Build Gradio app interface
- Launch Gradio app (final cell provides **public shareable URL**)

### 3. Configure via Gradio UI
Once launched:
- Select your base LLM from dropdown
- Enter preferred learning rate and batch size
- Upload `.csv` or `.jsonl` dataset
- Click **ğŸš€ Launch Fine-Tune**
- Status updates will stream directly in-app

---

## ğŸ§  Under the Hood

- **Framework**: Powered by Unsloth for efficiency and fast adapter-based tuning
- **Interface**: Gradio provides an accessible way to interact with hyperparameters without diving into backend code
- **Notebook Structure**: Modular cell layout enables easy adaptation into other training scripts or extensions like real-time training or leaderboard comparison

This project aims to lower the barrier to entry for LLM training by offering a sandbox-style simulator before diving into actual model weight updates.

---

## ğŸ§© Planned Enhancements

| Feature              | Status        | Notes |
|----------------------|---------------|-------|
| âœ… Gradio UI          | Complete       | Fully functional |
| ğŸ”„ Real Unsloth Tuning | In Progress   | Hook into `UnslothTrainer()` |
| ğŸ” WandB Integration   | Pending        | Track fine-tune metrics live |
| ğŸ”¬ Evaluation Suite   | Proposed       | Add BLEU, ROUGE, perplexity reports |

---

## ğŸ› ï¸ Contributing

Whether you're refining the UI, adding training logic, or porting to other platforms â€” pull requests are welcome!

1. Fork the repo
2. Create a feature branch
3. Document your changes clearly
4. Submit your PR with a descriptive commit message

---

## ğŸ“œ License

This project is licensed under the [MIT License](LICENSE).  
You're free to use it commercially, modify it, or build upon it.

---

## ğŸ“Œ Acknowledgements

- [Unsloth](https://github.com/unslothai/unsloth) for streamlined LLM training tools
- [Gradio](https://www.gradio.app/) for interactive UI components
- [HuggingFace](https://huggingface.co/) for providing open access model weights

---

## Notebook Link

https://colab.research.google.com/drive/1f6CyiVTY-p3k7NWmLOgsUsZhemxcP87r?usp=drive_link
